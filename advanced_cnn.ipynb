{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntermediateBlock(nn.Module):\n",
    "\n",
    "  \"\"\"\n",
    "  Class for the intermediate convolutional layer with architecture specifed by\n",
    "  assignment.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      input_channels = 3,\n",
    "      output_channels = 256,\n",
    "      output_volume = 32,\n",
    "      units = 4,\n",
    "      groups = True\n",
    "      ):\n",
    "    \"\"\"\n",
    "    input_channels:\n",
    "      The number of channels for incoming image\n",
    "    output_channels:\n",
    "      The number of channels for outgoing image\n",
    "    output_volume:\n",
    "      The size of the output image\n",
    "    units:\n",
    "      The number of convolutional units within the block\n",
    "    groups:\n",
    "      Whether to split inputs to groups for convolving\n",
    "    \"\"\"\n",
    "\n",
    "    super(IntermediateBlock, self).__init__()\n",
    "\n",
    "    self.units = units\n",
    "\n",
    "    if not groups:\n",
    "      self.groups = 1\n",
    "    else:\n",
    "      self.groups = input_channels\n",
    "\n",
    "    # Set up the feed-forward network with the same number of outputs as units\n",
    "    # for weighting each convolutional unit within block\n",
    "    self.fc = nn.Sequential(\n",
    "        nn.LayerNorm(input_channels),\n",
    "        nn.Linear(input_channels, 256),\n",
    "        nn.GELU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(256, self.units),\n",
    "        nn.Softmax(dim = 1)\n",
    "    )\n",
    "\n",
    "    # Each convolutional unit applies GELU activation function to outputs\n",
    "    # Adaptive Average Pooling is used to ensure output dimensionality is\n",
    "    # consistent\n",
    "    self.conv_layer = nn.ModuleList([\n",
    "        nn.Sequential(\n",
    "          nn.Conv2d(\n",
    "              input_channels,\n",
    "              output_channels,\n",
    "              groups = self.groups,\n",
    "              kernel_size = 8,\n",
    "              stride = 1,\n",
    "              padding = \"same\"\n",
    "              ),\n",
    "          nn.GELU(),\n",
    "          nn.AdaptiveAvgPool2d(output_volume)\n",
    "        )\n",
    "    ] * units)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # Calculate the mean of input x and pass it through a feed forward network\n",
    "    # This returns weights specifying which convolutional units to weigh more\n",
    "    m = torch.mean(x, dim = [2, 3])\n",
    "    a = self.fc(m)\n",
    "\n",
    "    # Calculate the output of each convolutional layer and multiply it by\n",
    "    # the corresponding coefficient generated by the feed forward network above\n",
    "    # Stack and sum outputs of each convolutional layer\n",
    "    conv_layer_out = []\n",
    "\n",
    "    for coef, unit in zip(a.T, self.conv_layer):\n",
    "      conv_out = unit(x)\n",
    "      coef = coef.reshape(-1,1,1,1)\n",
    "      conv_layer_out.append(torch.mul(coef, conv_out))\n",
    "\n",
    "    return torch.sum(torch.stack(conv_layer_out,dim = 0), dim = 0)\n",
    "\n",
    "class OutputBlock(nn.Module):\n",
    "\n",
    "  \"\"\"\n",
    "  Class for the output bloc with architecture specifed by assignment.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, input_channels, input_volume):\n",
    "\n",
    "    super(OutputBlock, self).__init__()\n",
    "\n",
    "    self.input_channels = input_channels\n",
    "    self.input_volume = input_volume\n",
    "\n",
    "    # Calculate size of flattened image for input layer to feed forward network\n",
    "    self.first_layer_inputs = (input_volume * input_volume * input_channels)\n",
    "\n",
    "    # Set up feed forward network\n",
    "    self.fc = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.LayerNorm(self.first_layer_inputs),\n",
    "      nn.Linear(self.first_layer_inputs, 10)\n",
    "  )\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # Calculate logits from feed forward network\n",
    "    logits = self.fc(x)\n",
    "\n",
    "    return logits\n",
    "\n",
    "class Residual(nn.Module):\n",
    "  \"\"\"\n",
    "  Wrapper class which pools the original input and adds it to the output\n",
    "  of the wrapped module.\n",
    "\n",
    "  https://github.com/kentaroy47/vision-transformers-cifar10/blob/main/models/convmixer.py\n",
    "  \"\"\"\n",
    "  def __init__(self, fn):\n",
    "    \"\"\"\n",
    "    fn:\n",
    "      The module being wrapped\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.fn = fn\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # Calculate the output from the forward pass of the wrapped module\n",
    "    output = self.fn(x)\n",
    "\n",
    "    # Change the dimensionality of x to match that of the output\n",
    "    residual = nn.AdaptiveMaxPool2d(output.shape[2])(x)\n",
    "\n",
    "    # Sum the output with the residual\n",
    "    return output + residual\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Self attention Layer\n",
    "\n",
    "    https://github.com/heykeetae/Self-Attention-GAN/blob/master/sagan_models.py\n",
    "    \"\"\"\n",
    "    def __init__(self,input_channels):\n",
    "\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "\n",
    "        self.query_conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "              in_channels = input_channels,\n",
    "              out_channels = input_channels//8,\n",
    "              kernel_size= 1\n",
    "              ),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.key_conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "              in_channels = input_channels,\n",
    "              out_channels = input_channels//8,\n",
    "              kernel_size= 1\n",
    "              ),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.value_conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "              in_channels = input_channels,\n",
    "              out_channels = input_channels,\n",
    "              kernel_size= 1\n",
    "              ),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.softmax  = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps (B x C x W x H)\n",
    "            returns :\n",
    "                out : self attention value + input feature\n",
    "                attention: B x N x N (N is Width*Height)\n",
    "        \"\"\"\n",
    "\n",
    "        batchsize, channels, width, height = x.size()\n",
    "\n",
    "        proj_query  = self.query_conv(x).view(\n",
    "            batchsize,\n",
    "            -1,\n",
    "            width * height\n",
    "            ).permute(0, 2, 1)\n",
    "\n",
    "        proj_key =  self.key_conv(x).view(\n",
    "            batchsize,\n",
    "            -1,\n",
    "            width * height\n",
    "            )\n",
    "\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "\n",
    "        attention = self.softmax(energy)\n",
    "        proj_value = self.value_conv(x).view(batchsize, -1, width * height) # B X C X N\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0,2,1) )\n",
    "        out = out.view(batchsize, channels, width, height)\n",
    "\n",
    "        out = self.gamma * out + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCNN(nn.Module):\n",
    "\n",
    "  \"\"\"\n",
    "  Class defining advanced convolutional architecture based on that specified in\n",
    "  assignment\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, block_config, self_attention = False):\n",
    "\n",
    "      \"\"\"\n",
    "      block_config:\n",
    "        Dictionary containing the configuration for each intermediate block\n",
    "      \"\"\"\n",
    "\n",
    "      super(AdvancedCNN, self).__init__()\n",
    "\n",
    "      # Set up empty sequential container to iteratively add blocks based on\n",
    "      # config dictionary\n",
    "      self.spine = nn.Sequential()\n",
    "\n",
    "      # Add first intermediate block to expand channels from 3 to 256\n",
    "      self.spine.append(nn.Sequential(\n",
    "        IntermediateBlock(\n",
    "            input_channels = 3,\n",
    "            output_channels = 256,\n",
    "            output_volume = 32,\n",
    "            units = 4,\n",
    "            groups = False\n",
    "        ),\n",
    "        nn.BatchNorm2d(256)\n",
    "        ))\n",
    "\n",
    "      # Iterate through config dictionary and add each block to spine\n",
    "      for i, block in enumerate(block_config.values()):\n",
    "\n",
    "        # Add intermediate block wrapped with the residual class\n",
    "        self.spine.append(\n",
    "            nn.Sequential(\n",
    "              Residual(\n",
    "                  IntermediateBlock(**block)\n",
    "                  ),\n",
    "              nn.BatchNorm2d(256)\n",
    "              )\n",
    "            )\n",
    "\n",
    "        # Add convolutional layer wrapped with residual layer\n",
    "        self.spine.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(256, 256, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(256)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if i in (0, 1, 2) and self_attention:\n",
    "\n",
    "          self.spine.append(\n",
    "              nn.Sequential(\n",
    "                  SelfAttention(256),\n",
    "                  nn.BatchNorm2d(256)\n",
    "              )\n",
    "          )\n",
    "\n",
    "      # Add adaptive pooling layer to reduce each channel to a number\n",
    "      # representing one feature\n",
    "      self.spine.append(nn.AdaptiveAvgPool2d((1,1)))\n",
    "\n",
    "      # Add output block\n",
    "      self.spine.append(OutputBlock(256, 1))\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    return self.spine(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            IntermediateBlock(\n",
    "                input_channels = 3,\n",
    "                output_channels = 256,\n",
    "                output_volume = 32,\n",
    "                units = 4,\n",
    "                groups = False\n",
    "            ),\n",
    "            nn.BatchNorm2d(256)\n",
    "            )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            IntermediateBlock(\n",
    "                input_channels = 256,\n",
    "                output_channels = 256,\n",
    "                output_volume = 32,\n",
    "                units = 4\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 1),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(256)\n",
    "            )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            IntermediateBlock(\n",
    "                input_channels = 256,\n",
    "                output_channels = 256,\n",
    "                output_volume = 26,\n",
    "                units = 4\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 1),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(256)\n",
    "            )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            IntermediateBlock(\n",
    "                input_channels = 256,\n",
    "                output_channels = 256,\n",
    "                output_volume = 20,\n",
    "                units = 4\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 1),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(256)\n",
    "            )\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            IntermediateBlock(\n",
    "                input_channels = 256,\n",
    "                output_channels = 256,\n",
    "                output_volume = 20,\n",
    "                units = 4\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 1),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(256)\n",
    "            )\n",
    "        \n",
    "        self.conv6 = nn.Sequential(\n",
    "            IntermediateBlock(\n",
    "                input_channels = 256,\n",
    "                output_channels = 256,\n",
    "                output_volume = 18,\n",
    "                units = 4\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 1),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(256)\n",
    "            )\n",
    "        \n",
    "        self.attn1 = nn.Sequential(\n",
    "                SelfAttention(256),\n",
    "                nn.BatchNorm2d(256)\n",
    "            )\n",
    "        \n",
    "        self.attn2 = nn.Sequential(\n",
    "                SelfAttention(256),\n",
    "                nn.BatchNorm2d(256)\n",
    "            )\n",
    "        \n",
    "        self.pool1 = nn.AdaptiveAvgPool2d((26, 26))\n",
    "        self.pool2 = nn.AdaptiveAvgPool2d((20, 20))\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d((18, 18))\n",
    "\n",
    "        \n",
    "        self.outpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.output = OutputBlock(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        c1 = self.conv1(x) + x\n",
    "        c2 = self.conv2(c1) + c1 + x\n",
    "        c3 = self.conv3(c2) + self.pool1(c2) + self.pool1(c1) + self.pool(x)\n",
    "        c4 = self.conv4(c3) + self.pool2(c3) + self.pool2(c2) + self.pool2(c1) + self.pool2(x)\n",
    "        a1 = self.attn1(c4) + c4 + self.pool2(c3) + self.pool2(c2) + self.pool2(c1) + self.pool2(x)\n",
    "        c5 = self.conv5(a1) + c4 + self.pool2(c3) + self.pool2(c2) + self.pool2(c1) + self.pool2(x) \n",
    "        a2 = self.attn2(c5) + c5 + c4 + self.pool2(c3) + self.pool2(c2) + self.pool2(c1) + self.pool2(x)\n",
    "        c6 = self.conv6(a2) + self.pool3(a2) + self.pool3(c5) + self.pool3(c4) + self.pool3(c3) + self.pool3(c2) + self.pool3(c1) + self.pool3(x)\n",
    "\n",
    "        out = self.outpool(c6)\n",
    "        out = self.output(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_block_config = {\n",
    "    \"block_1\": {\n",
    "        \"input_channels\": 256,\n",
    "        \"output_channels\": 256,\n",
    "        \"output_volume\": 32,\n",
    "        \"units\": 4,\n",
    "    },\n",
    "    \"block_2\": {\n",
    "        \"input_channels\": 256,\n",
    "        \"output_channels\": 256,\n",
    "        \"output_volume\": 26,\n",
    "        \"units\": 4,\n",
    "      },\n",
    "    \"block_3\": {\n",
    "        \"input_channels\": 256,\n",
    "        \"output_channels\": 256,\n",
    "        \"output_volume\": 20,\n",
    "        \"units\": 4,\n",
    "    },\n",
    "    \"block_4\": {\n",
    "        \"input_channels\": 256,\n",
    "        \"output_channels\": 256,\n",
    "        \"output_volume\": 20,\n",
    "        \"units\": 4,\n",
    "    },\n",
    "    \"block_5\": {\n",
    "        \"input_channels\": 256,\n",
    "        \"output_channels\": 256,\n",
    "        \"output_volume\": 18,\n",
    "        \"units\": 4,\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
